{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case scapy is needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --pre scapy[complete]\n",
    "\n",
    "# import scapy\n",
    "# from scapy.all import *\n",
    "\n",
    "# packets = rdpcap('/home/jovyan/work/A2/test.pcap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "\n",
    "# Plotting defaults\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.size'] = 12.0\n",
    "plt.rcParams['figure.figsize'] = 14.0, 7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data exported from splunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal=pd.read_csv(\"/home/jovyan/work/A2/a2_feat_flow_level_normal.csv\")\n",
    "df_attack=pd.read_csv(\"/home/jovyan/work/A2/a2_feat_flow_level_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can merge together both datasets just to explore a general relation between the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['src', 'dst', 'start', 'finish', 'total_duration', 'protocol',\n",
      "       'total_bytes', 'total_packets', 'src_ports', 'dst_ports', 'pps', 'bps',\n",
      "       'bpp', 'attack'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_normal['attack']=0\n",
    "df_attack['attack']=1\n",
    "df=pd.concat([df_normal,df_attack])\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform some basic exploration to look for correlation in the data.  \n",
    "We are interested in some of these features to perform a cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features=['total_duration',\n",
    "       'total_bytes', 'total_packets', 'src_ports', 'dst_ports', 'pps', 'bps',\n",
    "       'bpp', 'attack']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform categorical values to numerical (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Normal = StandardScaler().fit_transform(df_normal[selected_features])\n",
    "X_Attack = StandardScaler().fit_transform(df_attack[selected_features])\n",
    "X_All= StandardScaler().fit_transform(df[selected_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "scores = []\n",
    "clusters = range(2,5)\n",
    "for K in clusters:\n",
    "    \n",
    "    clusterer = KMeans(n_clusters=K)\n",
    "    cluster_labels = clusterer.fit_predict(X_Normal)\n",
    "    score = silhouette_score(X_Normal, cluster_labels)\n",
    "    scores.append(score)\n",
    "    print(k,\" done\")\n",
    "# Plot it out\n",
    "pd.DataFrame({'Num Clusters':clusters, 'score':scores}).plot(x='Num Clusters', y='score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So we know that the highest (closest to 1) silhouette score is at 10 clusters\n",
    "kmeans = KMeans(n_clusters=2).fit(X_Normal)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_attack=kmeans.predict(X_Attack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2,random_state=42).fit(X_Attack)\n",
    "print(\"Variability explained by the PC:\",sum(pca.explained_variance_ratio_) )\n",
    "reduced_data = pca.transform(X_Attack)\n",
    "\n",
    "# Now we can put our ML results back onto our dataframe!\n",
    "df_attack['cluster'] = labels_attack\n",
    "df_attack['x'] = reduced_data[:, 0] # Projection X Column\n",
    "df_attack['y'] = reduced_data[:, 1] # Projection Y Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use dataframe group by cluster\n",
    "cluster_groups = df_attack.groupby('cluster')\n",
    "\n",
    "# Plot the Machine Learning results\n",
    "colors = {-1:'black', 0:'green', 1:'blue', 2:'red', 3:'orange', 4:'purple', 5:'brown', 6:'pink', 7:'lightblue', 8:'grey', 9:'yellow'}\n",
    "fig, ax = plt.subplots()\n",
    "for key, group in cluster_groups:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', alpha=0.5, s=250,\n",
    "               label='Cluster: {:d}'.format(key), color=colors[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE is a great projection algorithm. In this case we're going from 12 dimensions to 2\n",
    "projection = TSNE().fit_transform(X_Normal)\n",
    "\n",
    "# Now we can put our ML results back onto our dataframe!\n",
    "df_normal['cluster'] = labels_attack\n",
    "df_normal['x'] = reduced_data[:, 0] # Projection X Column\n",
    "df_normal['y'] = reduced_data[:, 1] # Projection Y Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use dataframe group by cluster\n",
    "cluster_groups = df_normal.groupby('cluster')\n",
    "\n",
    "# Plot the Machine Learning results\n",
    "colors = {-1:'black', 0:'green', 1:'blue', 2:'red', 3:'orange', 4:'purple', 5:'brown', 6:'pink', 7:'lightblue', 8:'grey', 9:'yellow'}\n",
    "fig, ax = plt.subplots()\n",
    "for key, group in cluster_groups:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', alpha=0.5, s=250,\n",
    "               label='Cluster: {:d}'.format(key), color=colors[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now print out the details for each cluster\n",
    "pd.set_option('display.width', 1000)\n",
    "for key, group in cluster_groups:\n",
    "    print('\\nCluster {:d}: {:d} observations'.format(key, len(group)))\n",
    "    print(group[features].head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now try DBScan\n",
    "eps=100\n",
    "min_samples=20\n",
    "dbscan=DBSCAN(eps=eps, min_samples=min_samples,algorithm='ball_tree', metric='euclidean').fit(X_Normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_attack['cluster_db'] = dbscan.predict(X_Attack)\n",
    "print('Number of Clusters: {:d}'.format(df_attack['cluster_db'].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use dataframe group by cluster\n",
    "cluster_groups = df_normal.groupby('cluster_db')\n",
    "\n",
    "# Plot the Machine Learning results\n",
    "fig, ax = plt.subplots()\n",
    "for key, group in cluster_groups:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', alpha=0.5, s=250,\n",
    "               label='Cluster: {:d}'.format(key), color=colors[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import OPTICS, cluster_optics_dbscan\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust = OPTICS(min_samples=50, xi=.05, min_cluster_size=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust.fit(X_Normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
