{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "import preprocessing\n",
    "import cconfig\n",
    "import clustering\n",
    "import utils\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting defaults\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select type of features and default values\n",
    "#dataset_type=cconfig.DATASET_TYPE_FLOW\n",
    "dataset_type=cconfig.DATASET_TYPE_BIFLOW\n",
    "#selected_features=cconfig.SELECTED_FEATURES_UFLOW\n",
    "selected_features=cconfig.SELECTED_FEATURES_BIFLOW\n",
    "max_num_clusters=cconfig.DEFAULT_NUM_CLUSTERS\n",
    "sort_anomalies=cconfig.BIFLOW_ANOMALIES_SORT\n",
    "#sort_anomalies=cconfig.FLOW_ANOMALIES_SORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original data in dataframes, sample, select some features and scale\n",
    "df,df_Normal,df_Attack=preprocessing.data_load(1,None,False,dataset_type)\n",
    "print(df.columns)\n",
    "X=preprocessing.data_scale(df[selected_features])\n",
    "X_Normal=preprocessing.data_scale(df_Normal[selected_features])\n",
    "X_Attack=preprocessing.data_scale(df_Attack[selected_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(utils.get_time,\"Kmeans\")\n",
    "\n",
    "# find the best number of clusters\n",
    "df_silhouette = clustering.kmeans_get_number_clusters(X_Normal,max_num_clusters)\n",
    "\n",
    "# select best number of clusters for kmeans\n",
    "max_num_clusters=df_silhouette.iloc[df_silhouette.score.idxmax() ]['Num Clusters']\n",
    "\n",
    "# saving results\n",
    "utils.save(df_silhouette,dataset_type+\"_silhouette\")\n",
    "print(\"The number of clusters is: \",max_num_clusters)\n",
    "\n",
    "# plot the result for reference\n",
    "df_silhouette.plot(x='Num Clusters', y='score')\n",
    "\n",
    "print(\"The number of clusters is: \",max_num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit kmeans model with normal day data\n",
    "#kmeans=clustering.kmeans_train(X_Normal,int(max_num_clusters))\n",
    "\n",
    "# predictions with attack dataset\n",
    "#labels=clustering.kmeans_predict(X_Attack,kmeans)\n",
    "kmeans,labels=clustering.kmeans_fit_predict(X_Normal,X_Attack,int(max_num_clusters))\n",
    "\n",
    "\n",
    "# save predictions kmeans\n",
    "utils.save(labels,dataset_type+\"_prediction_kmeans\")\n",
    "\n",
    "# dimensionality reduction\n",
    "XR=preprocessing.get_pc(X_Attack,2)\n",
    "\n",
    "# print results\n",
    "clustering.clustering_print_results(df_Attack,labels,selected_features,XR,True,True,dataset_type+'_kmeans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance proximity based to centroids\n",
    "index_anomalies=clustering.kmeans_anomalies_proximity(X_Attack,kmeans)\n",
    "df_anomalies_kmeans_anomalies_proximity=df_Attack.iloc[index_anomalies,:]\n",
    "df_anomalies_kmeans_anomalies_proximity.sort_values(by=sort_anomalies,ascending=False)\n",
    "utils.save(df_anomalies_kmeans_anomalies_proximity,dataset_type+\"_df_anomalies_kmeans_anomalies_proximity\")\n",
    "df_anomalies_kmeans_anomalies_proximity.to_csv(\"../outputs/\"+dataset_type+\"_df_anomalies_kmeans_anomalies_proximity\"+\".csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extreme value analysis\n",
    "df_anomalies_kmeans_z=clustering.kmeans_anomalies_extreme_values(df_Attack,X_Attack,kmeans,labels)\n",
    "\n",
    "# save anomalies\n",
    "utils.save(df_anomalies_kmeans_z,dataset_type+\"_df_anomalies_kmeans_z\")\n",
    "df_anomalies_kmeans_z.to_csv(\"../outputs/\"+dataset_type+\"_df_anomalies_kmeans_z\"+\".csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "df_anomalies_kmeans_z.src_ip.value_counts()[:10].plot.pie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomalies_kmeans_z.dst_ip.value_counts()[:10].plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper parameters for dbscan\n",
    "eps=cconfig.DEFAULT_EPS\n",
    "min_samples=cconfig.DEFAULT_MIN_SAMPLES\n",
    "\n",
    "# fit and predict\n",
    "labels=clustering.dbscan_fit_predict(eps,min_samples,X)\n",
    "# save predictions kmeans\n",
    "utils.save(labels,dataset_type+\"_prediction_dbscan\")\n",
    "\n",
    "# do dimensionality reduction to plot\n",
    "XR=preprocessing.get_pc(X,2)\n",
    "\n",
    "# print and plot\n",
    "clustering.clustering_print_results(df,dblabels,selected_features,XR,True,True,dataset_type+'_dbscan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyper params for optics\n",
    "eps=cconfig.DEFAULT_EPS\n",
    "min_samples=cconfig.DEFAULT_MIN_SAMPLES\n",
    "\n",
    "# predict using optics\n",
    "labels=clustering.optics_fit_predict(X,min_samples,'dbscan', eps)\n",
    "\n",
    "# save predictions kmeans\n",
    "utils.save(labels,dataset_type+\"_prediction_optic\")\n",
    "\n",
    "# do dimensionality reduction to plot\n",
    "XR=preprocessing.get_pc(X,2)\n",
    "\n",
    "# print and plot\n",
    "clustering.clustering_print_results(df,labels,selected_features,XR,True,True,dataset_type+'_optic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anomalies_optic=clustering.optics_anomalies(df,labels)\n",
    "df_anomalies_optic.sort_values(by=sort_anomalies,ascending=False)\n",
    "\n",
    "# save anomalies\n",
    "utils.save(df_anomalies_optic,dataset_type+\"_df_anomalies_optic\")\n",
    "df_anomalies_optic.to_csv(\"../outputs/\"+dataset_type+\"_df_anomalies_optic\"+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IFOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model iforest\n",
    "iforest=clustering.iforest_train(X_Normal,cconfig.DEAFULT_CONTAMINATION)\n",
    "labels=clustering.iforest_predict(X_Attack,iforest)\n",
    "\n",
    "# save predictions kmeans\n",
    "utils.save(labels,dataset_type+\"_prediction_iforest\")\n",
    "\n",
    "# dimensionality reduction\n",
    "XR=preprocessing.get_pc(X_Attack,2)\n",
    "\n",
    "# print results\n",
    "clustering.clustering_print_results(df_Attack,labels,selected_features,XR,True,True,dataset_type+'_iforest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get anomalies\n",
    "df_anomalies_iforest=clustering.iforest_anomalies(df_Attack,labels)\n",
    "df_anomalies_iforest.sort_values(by=sort_anomalies,ascending=False)\n",
    "# save anomalies\n",
    "utils.save(df_anomalies_iforest,dataset_type+\"_df_anomalies_iforest\")\n",
    "df_anomalies_iforest.to_csv(\"../outputs/\"+dataset_type+\"_df_anomalies_iforest\"+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_fraction=cconfig.DEAFULT_CONTAMINATION\n",
    "n_neighbors=cconfig.N_NEIGHBOURS\n",
    "labels=clustering.lof_fit_predict(X,outliers_fraction,n_neighbors)\n",
    "\n",
    "# save predictions kmeans\n",
    "utils.save(labels,dataset_type+\"_prediction_lof\")\n",
    "\n",
    "# dimensionality reduction\n",
    "XR=preprocessing.get_pc(X,2)\n",
    "\n",
    "# print results\n",
    "clustering.clustering_print_results(df,labels,selected_features,XR,True,True,dataset_type+'_lof')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get anomalies\n",
    "df_anomalies_lof=clustering.lof_anomalies(df,labels)\n",
    "df_anomalies_lof.sort_values(by=sort_anomalies,ascending=False)\n",
    "\n",
    "# save anomalies\n",
    "utils.save(df_anomalies_lof,dataset_type+\"_df_anomalies_lof\")\n",
    "df_anomalies_lof.to_csv(\"../outputs/\"+dataset_type+\"_df_anomalies_lof\"+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test the model\n",
    "outliers_fraction=cconfig.DEAFULT_CONTAMINATION\n",
    "labels=clustering.ocsvm_fit_predict(X_Normal,X_Attack,outliers_fraction)\n",
    "utils.save(labels,dataset_type+\"_prediction_ocsvm\")\n",
    "\n",
    "# dimensionality reduction\n",
    "XR=preprocessing.get_pc(X_Attack,2)\n",
    "\n",
    "# print results\n",
    "clustering.clustering_print_results(df_Attack,labels,selected_features,XR,True,True,dataset_type+'_ocsvm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get anomalies\n",
    "df_anomalies_ocsvm=clustering.ocsvm_anomalies(df_Attack,labels)\n",
    "df_anomalies_ocsvm.sort_values(by=sort_anomalies,ascending=False)\n",
    "# save anomalies\n",
    "utils.save(df_anomalies_ocsvm,dataset_type+\"_df_anomalies_ocsvm\")\n",
    "df_anomalies_ocsvm.to_csv(\"../outputs/\"+dataset_type+\"_df_anomalies_ocsvm\"+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
